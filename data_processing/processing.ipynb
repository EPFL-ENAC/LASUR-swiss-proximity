{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import h3\n",
    "import h3pandas\n",
    "from shapely.geometry import Polygon\n",
    "import numpy\n",
    "import pydeck as pdk\n",
    "import h3pandas\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define paths and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "data_folder = os.path.join(root_folder, \"source_data\")\n",
    "geojson_folder = os.path.join(root_folder, \"geojson\")\n",
    "path_demand_h3 = os.path.join(data_folder,\"demand\", \"ALL_2017_2050_share_of_trips_h3.pkl\")\n",
    "path_demand_polygon = os.path.join(data_folder,\"demand\", \"ALL_2017_2050_share_of_trips_taz.pkl\")\n",
    "path_demand_geneva_h3 = os.path.join(data_folder,\"demand\", \"Geneva_mmt_2015_2023_share_of_trips_h3.pkl\")\n",
    "path_supply_h3 = os.path.join(data_folder,\"supply\", \"All_CH_access_light_H3.pkl\")\n",
    "path_supply_polygon = os.path.join(data_folder,\"supply\", \"All_CH_access_light_TAZ.pkl\")\n",
    "path_verkehrszonen = os.path.join(data_folder, \"verkehrszonen.gpkg\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load demand h3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path_demand_h3, compression='gzip')\n",
    "df = df[df['h3index'].notna()]\n",
    "df['h3index_int'] = df['h3index'].astype(numpy.int64)\n",
    "df['h3index'] = df['h3index_int'].apply(lambda x: h3.int_to_str(x))\n",
    "df.set_index('h3index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's pivot the data to have separate columns for each year and proximity threshold combination\n",
    "df_combined = df.pivot_table(\n",
    "    index='h3index',\n",
    "    columns=['Proximity_threshold','Year' ],\n",
    "    values=['Fuss', 'Velo', 'OeV', 'Auto', 'All_modes'],\n",
    "    aggfunc='first'  # Use 'first' since there should be only one value per combination\n",
    ")\n",
    "\n",
    "# Flatten the multi-level column names\n",
    "df_combined.columns = [f'{col[0]}_{col[1]}_{col[2]}' for col in df_combined.columns]\n",
    "\n",
    "# Keep the Agglo column (it should be the same for all rows with same h3index)\n",
    "df_combined['Agglo'] = df.groupby('h3index')['Agglo'].first()\n",
    "\n",
    "\n",
    "\n",
    "# Reset index to have h3index as a column for h3pandas operations\n",
    "df_combined = df_combined.reset_index()\n",
    "df_combined = df_combined.set_index('h3index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level9 = df_combined.copy()\n",
    "df_level9 = df_level9.h3.h3_to_geo_boundary()\n",
    "numeric_cols = df_level9.select_dtypes(include=[numpy.number]).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    # Round all values\n",
    "    rounded_col = df_level9[col].round(4)\n",
    "    # Replace exact zeros back to 0 (not 0.0000)\n",
    "    df_level9[col] = numpy.where(df_level9[col] == 0, 0, rounded_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def aggregation(series):\n",
    "    if(series.name == 'Agglo'):\n",
    "        return series.iloc[0]\n",
    "    else:\n",
    "        return series.mean().round(4)  # Example: return the mean of the series\n",
    "\n",
    "def to_parent_aggregate(df,level):\n",
    "    return  df.h3.h3_to_parent_aggregate(\n",
    "    level,\n",
    "    operation=aggregation\n",
    "    )\n",
    "def h3_to_geojson(df, level):\n",
    "    gdf = gpd.GeoDataFrame(df)\n",
    "\n",
    "    # Convert to GeoJSON string with drop_id option, then write to file\n",
    "    geojson_str = gdf.to_json(drop_id=True)\n",
    "\n",
    "    # Write the GeoJSON string to file\n",
    "    with open(os.path.join(\"geojson\", \"demand_h3_level_\"+level+\".geojson\"), 'w') as f:\n",
    "        f.write(geojson_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to level 6\n",
    "df_level6 = to_parent_aggregate(df_combined, 6)\n",
    "\n",
    "# Aggregate to level 7\n",
    "df_level7 = to_parent_aggregate(df_combined, 7)\n",
    "# Aggregate to level 8\n",
    "df_level8 = to_parent_aggregate(df_combined, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_to_geojson(df_level6, \"6\")\n",
    "h3_to_geojson(df_level7, \"7\")\n",
    "h3_to_geojson(df_level8, \"8\")\n",
    "h3_to_geojson(df_level9, \"9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for pydeck H3 layer\n",
    "df_viz = df_level9.copy()\n",
    "df_viz = df_viz[df_viz['All_modes_3800_2050'] > 0.1]\n",
    "# Reset index to get h3index as a column\n",
    "# df_viz = df_viz.sample(frac=0.5)\n",
    "df_viz\n",
    "df_viz['hex'] = df_viz.index\n",
    "\n",
    "df_viz['value'] = (df_viz['All_modes_3800_2050'] * 255).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = pdk.Layer(\n",
    "    \"H3HexagonLayer\",\n",
    "    df_viz,\n",
    "    pickable=True,\n",
    "    stroked=False,\n",
    "    filled=True,\n",
    "    extruded=False,\n",
    "    get_hexagon=\"hex\",\n",
    "    get_fill_color=\"[255 - value, 100, value, 180]\",  # Red to blue gradient with transparency\n",
    ")\n",
    "# Set the viewport to Switzerland\n",
    "view_state = pdk.ViewState(\n",
    "    latitude=46.8182,  # Switzerland center\n",
    "    longitude=8.2275,\n",
    "    zoom=7,\n",
    "    bearing=0,\n",
    "    pitch=0,\n",
    ")\n",
    "# Create the deck\n",
    "r = pdk.Deck(\n",
    "    layers=[layer],\n",
    "    initial_view_state=view_state,\n",
    "    tooltip={\"text\": \"H3 Index: {hex}\\nAll modes: {All_modes}\\nAgglo: {Agglo}\\nYear: {Year}\"},\n",
    ")\n",
    "r.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load supply h3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path_supply_h3, compression='gzip')\n",
    "df = df[df['h3index'].notna()]\n",
    "df['h3index_int'] = df['h3index'].astype(numpy.int64)\n",
    "df['h3index'] = df['h3index_int'].apply(lambda x: h3.int_to_str(x))\n",
    "df.set_index('h3index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's pivot the data to have separate columns for each year and proximity threshold combination\n",
    "df_combined = df.pivot_table(\n",
    "    index='h3index',\n",
    "    columns=['poi_kind' ],\n",
    "    values=['1', '2', '3', '4', '5'],\n",
    "    aggfunc='first'  # Use 'first' since there should be only one value per combination\n",
    ")\n",
    "\n",
    "# Flatten the multi-level column names\n",
    "df_combined.columns = [f'{col[0]}_{col[1]}' for col in df_combined.columns]\n",
    "\n",
    "# Keep the Agglo column (it should be the same for all rows with same h3index)\n",
    "df_combined['Agglo'] = df.groupby('h3index')['agglo'].first()\n",
    "\n",
    "\n",
    "\n",
    "# Reset index to have h3index as a column for h3pandas operations\n",
    "df_combined = df_combined.reset_index()\n",
    "df_combined = df_combined.set_index('h3index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation(series):\n",
    "    if(series.name == 'Agglo'):\n",
    "        return series.iloc[0]\n",
    "    else:\n",
    "        return int(series.mean())\n",
    "    \n",
    "def to_parent_aggregate(df,level):\n",
    "    return  df.h3.h3_to_parent_aggregate(\n",
    "    level,\n",
    "    operation=aggregation\n",
    "    )\n",
    "def supply_h3_to_geojson(df, level):\n",
    "    gdf = gpd.GeoDataFrame(df)\n",
    "\n",
    "    # Convert to GeoJSON string with drop_id option, then write to file\n",
    "    geojson_str = gdf.to_json(drop_id=True)\n",
    "\n",
    "    # Write the GeoJSON string to file\n",
    "    with open(os.path.join(\"geojson\", \"supply_h3_level_\"+level+\".geojson\"), 'w') as f:\n",
    "        f.write(geojson_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to level 6\n",
    "df_level6 = to_parent_aggregate(df_combined, 6)\n",
    "\n",
    "# Aggregate to level 7\n",
    "df_level7 = to_parent_aggregate(df_combined, 7)\n",
    "# Aggregate to level 8\n",
    "df_level8 = to_parent_aggregate(df_combined, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_level9 = df_combined.copy()\n",
    "df_level9 = df_level9.h3.h3_to_geo_boundary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_h3_to_geojson(df_level6, \"6\")\n",
    "supply_h3_to_geojson(df_level7, \"7\")\n",
    "supply_h3_to_geojson(df_level8, \"8\")\n",
    "supply_h3_to_geojson(df_level9, \"9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demand polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the verkehrszonen\n",
    "df_verkehrszonen = gpd.read_file(path_verkehrszonen)\n",
    "# df_verkehrszonen = df_verkehrszonen.drop_duplicates(subset=['id_zone'])\n",
    "# set index to the verkehrszonen\n",
    "df_verkehrszonen.set_index('id_zone', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the demand data \n",
    "df_demand_polygon = pd.read_pickle(path_demand_polygon, compression='gzip')\n",
    "df_demand_polygon.set_index('Origin', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataframe shape: (5896, 31)\n"
     ]
    }
   ],
   "source": [
    "# First, let's pivot the data to have separate columns for each year and proximity threshold combination\n",
    "df_combined = df_demand_polygon.pivot_table(\n",
    "    index='Origin',\n",
    "    columns=['Proximity_threshold','Year' ],\n",
    "    values=['Fuss', 'Velo', 'OeV', 'Auto', 'All_modes'],\n",
    "    aggfunc='first'  # Use 'first' since there should be only one value per combination\n",
    ")\n",
    "\n",
    "# Flatten the multi-level column names\n",
    "df_combined.columns = [f'{col[0]}_{col[1]}_{col[2]}' for col in df_combined.columns]\n",
    "\n",
    "# Keep the Agglo column (it should be the same for all rows with same h3index)\n",
    "df_combined['Agglo'] = df_demand_polygon.groupby('Origin')['Agglo'].first()\n",
    "\n",
    "# Reset index to have h3index as a column for h3pandas operations\n",
    "df_combined = df_combined.reset_index()\n",
    "df_combined = df_combined.set_index('Origin')\n",
    "\n",
    "print(f\"Combined dataframe shape: {df_combined.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demand_polygon = df_combined.merge(\n",
    "    df_verkehrszonen[['geometry']], \n",
    "    left_on='Origin', \n",
    "    right_index=True, \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df_demand_polygon)\n",
    "geojson_str = gdf.to_json(drop_id=True)\n",
    "\n",
    "with open(os.path.join(\"geojson\", \"demand_polygon.geojson\"), 'w') as f:\n",
    "    f.write(geojson_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supply polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the demand data \n",
    "df_supply_polygon = pd.read_pickle(path_supply_polygon, compression='gzip')\n",
    "df_supply_polygon.set_index('taz_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>poi_kind</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>agglo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taz_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101001</th>\n",
       "      <td>All</td>\n",
       "      <td>2725</td>\n",
       "      <td>3273</td>\n",
       "      <td>3364</td>\n",
       "      <td>3417</td>\n",
       "      <td>3525</td>\n",
       "      <td>Zürich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101001</th>\n",
       "      <td>Any</td>\n",
       "      <td>361</td>\n",
       "      <td>456</td>\n",
       "      <td>570</td>\n",
       "      <td>617</td>\n",
       "      <td>674</td>\n",
       "      <td>Zürich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101001</th>\n",
       "      <td>Care</td>\n",
       "      <td>2482</td>\n",
       "      <td>3228</td>\n",
       "      <td>3294</td>\n",
       "      <td>3337</td>\n",
       "      <td>3361</td>\n",
       "      <td>Zürich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101001</th>\n",
       "      <td>Catering</td>\n",
       "      <td>940</td>\n",
       "      <td>1744</td>\n",
       "      <td>2091</td>\n",
       "      <td>2276</td>\n",
       "      <td>2352</td>\n",
       "      <td>Zürich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101001</th>\n",
       "      <td>Culture</td>\n",
       "      <td>985</td>\n",
       "      <td>2014</td>\n",
       "      <td>2574</td>\n",
       "      <td>3117</td>\n",
       "      <td>3230</td>\n",
       "      <td>Zürich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841413002</th>\n",
       "      <td>Provision</td>\n",
       "      <td>1238</td>\n",
       "      <td>1530</td>\n",
       "      <td>1816</td>\n",
       "      <td>2052</td>\n",
       "      <td>2346</td>\n",
       "      <td>Como-Chiasso-Mendrisio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841413002</th>\n",
       "      <td>Public</td>\n",
       "      <td>1669</td>\n",
       "      <td>1856</td>\n",
       "      <td>1941</td>\n",
       "      <td>2189</td>\n",
       "      <td>2262</td>\n",
       "      <td>Como-Chiasso-Mendrisio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841413002</th>\n",
       "      <td>Shopping</td>\n",
       "      <td>1115</td>\n",
       "      <td>1415</td>\n",
       "      <td>1545</td>\n",
       "      <td>1811</td>\n",
       "      <td>2030</td>\n",
       "      <td>Como-Chiasso-Mendrisio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841413002</th>\n",
       "      <td>Sport</td>\n",
       "      <td>787</td>\n",
       "      <td>1141</td>\n",
       "      <td>1368</td>\n",
       "      <td>1466</td>\n",
       "      <td>1569</td>\n",
       "      <td>Como-Chiasso-Mendrisio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841413002</th>\n",
       "      <td>Transport</td>\n",
       "      <td>1719</td>\n",
       "      <td>2012</td>\n",
       "      <td>2413</td>\n",
       "      <td>2550</td>\n",
       "      <td>2711</td>\n",
       "      <td>Como-Chiasso-Mendrisio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88992 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            poi_kind     1     2     3     4     5                   agglo\n",
       "taz_id                                                                    \n",
       "101001           All  2725  3273  3364  3417  3525                  Zürich\n",
       "101001           Any   361   456   570   617   674                  Zürich\n",
       "101001          Care  2482  3228  3294  3337  3361                  Zürich\n",
       "101001      Catering   940  1744  2091  2276  2352                  Zürich\n",
       "101001       Culture   985  2014  2574  3117  3230                  Zürich\n",
       "...              ...   ...   ...   ...   ...   ...                     ...\n",
       "841413002  Provision  1238  1530  1816  2052  2346  Como-Chiasso-Mendrisio\n",
       "841413002     Public  1669  1856  1941  2189  2262  Como-Chiasso-Mendrisio\n",
       "841413002   Shopping  1115  1415  1545  1811  2030  Como-Chiasso-Mendrisio\n",
       "841413002      Sport   787  1141  1368  1466  1569  Como-Chiasso-Mendrisio\n",
       "841413002  Transport  1719  2012  2413  2550  2711  Como-Chiasso-Mendrisio\n",
       "\n",
       "[88992 rows x 7 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_supply_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_supply_polygon.pivot_table(\n",
    "    index='taz_id',\n",
    "    columns=['poi_kind' ],\n",
    "    values=['1', '2', '3', '4', '5'],\n",
    "    aggfunc='first'  # Use 'first' since there should be only one value per combination\n",
    ")\n",
    "df_combined.columns = [f'{col[0]}_{col[1]}' for col in df_combined.columns]\n",
    "df_combined['Agglo'] = df_supply_polygon.groupby('taz_id')['agglo'].first()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_supply_polygon = df_combined.merge(\n",
    "    df_verkehrszonen[['geometry']], \n",
    "    left_on='taz_id', \n",
    "    right_index=True, \n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(df_supply_polygon)\n",
    "geojson_str = gdf.to_json(drop_id=True)\n",
    "\n",
    "with open(os.path.join(\"geojson\", \"supply_polygon.geojson\"), 'w') as f:\n",
    "    f.write(geojson_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
